{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "luna.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOCqsCZlHyi4OuxgGrdgmx7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raffaelepojer/DeepLearningAssignment/blob/DL_luna/luna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6qVu3yRaYv8"
      },
      "source": [
        "# Accessing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAL3hQ8oaOe0"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "%cd /content/gdrive/MyDrive/dataset\\ elisa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cosPyYuPaTrn"
      },
      "source": [
        "# Start importing the dataset in pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfuN0JlzafJF"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P23YT0gzakvl"
      },
      "source": [
        "df = pd.read_csv('annotations_train.csv')\n",
        "tmp = df.iloc[df.index[df['id'] == 474], 1:]\n",
        "tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4XGkSJOanfW"
      },
      "source": [
        "class ElyImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "\n",
        "        self.imgs = os.listdir(img_dir)\n",
        "        self.img_list = self.imgs\n",
        "\n",
        "        self.imgs = [el for el in self.imgs if os.path.splitext(el)[1] == '.jpg']\n",
        "        self.lb_ids = [int(el.split('_')[0]) for el in self.imgs]\n",
        "        self.lb_cams = [int(el.split('_')[1][1]) for el in self.imgs]\n",
        "        self.imgs = [os.path.join(img_dir, el) for el in self.imgs]\n",
        "\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_list[idx])\n",
        "        image = read_image(img_path)\n",
        "        id = self.lb_ids[idx]\n",
        "\n",
        "        label = torch.tensor(self.img_labels.iloc[\n",
        "                                                  self.img_labels.index[self.img_labels['id'] == self.lb_ids[idx]], 1:].values)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, id, label\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZoaQHo3arIW"
      },
      "source": [
        "training_data = ElyImageDataset('annotations_train.csv', 'train/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS1RJGtjatjl"
      },
      "source": [
        "# Show 4 samples in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GKUcQBWavzc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "for i in range(len(training_data)):\n",
        "    image, id, label = training_data[i]\n",
        "\n",
        "    print(i, image.shape, id)\n",
        "\n",
        "    ax = plt.subplot(1, 4, i + 1)\n",
        "    plt.tight_layout()\n",
        "    ax.set_title('Sample #{}'.format(i))\n",
        "    ax.axis('off')\n",
        "\n",
        "    plt.imshow(image[0], cmap='gray')\n",
        "\n",
        "    if i == 3:\n",
        "        plt.show()\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMQ5vvbua1DU"
      },
      "source": [
        "labels_map = {\n",
        "    0: {\n",
        "        1: 'young',\n",
        "        2: 'teenager',\n",
        "        3: 'adult',\n",
        "        4: 'old'\n",
        "    },\n",
        "    1: {\n",
        "        1: 'no backpack',\n",
        "        2: 'yes backpack'\n",
        "    },\n",
        "    2: {\n",
        "        1: 'no bag',\n",
        "        2: 'yes bag'\n",
        "    },\n",
        "    3: {\n",
        "        1: 'no handbag',\n",
        "        2: 'yes handbag'\n",
        "    },\n",
        "    4: {\n",
        "        1: 'dress',\n",
        "        2: 'pants'\n",
        "    },\n",
        "    5: {\n",
        "        1: 'long lower body clothing',\n",
        "        2: 'short'\n",
        "    },\n",
        "    6: {\n",
        "        1: 'long sleeve',\n",
        "        2: 'short sleeve'\n",
        "    },\n",
        "    7: {\n",
        "        1: 'short hair',\n",
        "        2: 'long hair'\n",
        "    },\n",
        "    8: {\n",
        "        1: 'no hat',\n",
        "        2: 'yes hat'\n",
        "    },\n",
        "    9: {\n",
        "        1: 'male',\n",
        "        2: 'female'\n",
        "    },\n",
        "    10: {\n",
        "        1: 'no upblack',\n",
        "        2: 'yes upblcak'\n",
        "    },\n",
        "    11: {\n",
        "        1: 'no upwhite',\n",
        "        2: 'yes upwhite'\n",
        "    },\n",
        "    12: {\n",
        "        1: 'no upred',\n",
        "        2: 'yes upred'\n",
        "    },\n",
        "    13: {\n",
        "        1: 'no uppurle',\n",
        "        2: 'yes uppurle'\n",
        "    },\n",
        "    14: {\n",
        "        1: 'no upyellow',\n",
        "        2: 'yes upyellow'\n",
        "    },\n",
        "    15: {\n",
        "        1: 'no upgray',\n",
        "        2: 'yes upgray'\n",
        "    },\n",
        "    16: {\n",
        "        1: 'no upblue',\n",
        "        2: 'yes upblue'\n",
        "    },\n",
        "    17: {\n",
        "        1: 'no upgreen',\n",
        "        2: 'yes upgreen'\n",
        "    },\n",
        "    18: {\n",
        "        1: 'no downblack',\n",
        "        2: 'yes downblcak'\n",
        "    },\n",
        "    19: {\n",
        "        1: 'no downwhite',\n",
        "        2: 'yes downwhite'\n",
        "    },\n",
        "    20: {\n",
        "        1: 'no downpink',\n",
        "        2: 'yes downpink'\n",
        "    },\n",
        "    21: {\n",
        "        1: 'no downpurple',\n",
        "        2: 'yes downpurple'\n",
        "    },\n",
        "    22: {\n",
        "        1: 'no downyellow',\n",
        "        2: 'yes downyellow'\n",
        "    },\n",
        "    23: {\n",
        "        1: 'no downgray',\n",
        "        2: 'yes downgray'\n",
        "    },\n",
        "    24: {\n",
        "        1: 'no downblue',\n",
        "        2: 'yes downblue'\n",
        "    },\n",
        "    25: {\n",
        "        1: 'no downgreen',\n",
        "        2: 'yes downgreen'\n",
        "    },\n",
        "    26: {\n",
        "        1: 'no downbrown',\n",
        "        2: 'yes downbrown'\n",
        "    }    \n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GdqDyTLa3GM"
      },
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "\n",
        "train_features, train_ids, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0]\n",
        "label = train_labels[0].squeeze()\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "plt.show()\n",
        "\n",
        "for i in range(len(label)):\n",
        "  print(labels_map[i][label[i].item()])\n",
        "\n",
        "print(f\"Label: {label}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}